# ğŸ¤– Multimodal Zero-Shot Activity Recognition for Process Mining of Robotic Systems

> **Understanding what a robot has done by observing video + audio, without training a model.**  
> âœ… Activity recognition â†’ âœ… Event log â†’ âœ… Process mining (DFG)

---

## ğŸ“Œ Project Objective

This project implements a pipeline to **observe a robot**, **recognize the activities it performs**, and **reconstruct the process of its actions**.

In short:

1. The robot is monitored via **video + audio**  
2. A multimodal foundation model recognises activities in a **zero-shot** manner (no task-specific training)  
3. The activities are converted into an **event log**  
4. We apply **process mining** to derive a process model (DFG)

---

## ğŸ§  Key Idea

This project leverages **multimodal foundation models** (e.g., LLava / Phi-Vision / Llama-Vision) to perform **zero-shot activity recognition** in a robotic setting.

### Why this matters

- ğŸš« No bespoke training required  
- âš™ï¸ Easily portable to different robots/scenarios by *just changing the prompt*  
- ğŸ¯ Ideal for industrial robotic scenarios or where custom training is infeasible

---

## ğŸ¥ Dataset / Scenario

Following the referenced paper, the robot manipulates objects (e.g., Baxter UR5 dataset) and performs activities such as:

| Activity | Description |
|---|---|
| grasp | grasping an object |
| pick | lifting it |
| hold | holding it |
| shake | manipulating it |
| lower | lowering it |
| drop | releasing an object (audio helps detect this!) |

We combine **video + audio** modalities for higher reliability:

ğŸ–¼ï¸ Video = good for most actions  
ğŸ”Š Audio = especially helpful to detect *drop* events

---

## ğŸ“‚ Architecture

| Step | Description | Technology |
|---|---|---|
| 1 | Extract frames from video + audio chunks | C# + FFmpeg wrapper |
| 2 | Multimodal prompt for zero-shot activity recognition | Semantic Kernel + Ollama |
| 3 | Recognize activities | vision model (LLava / Phi-Vision / Moondream / Llama-Vision) |
| 4 | Audio + video fusion logic | C# |
| 5 | Generate event log in CSV (`<caseId, timestamp, activity>`) | C# |
| 6 | Perform process mining â†’ derive DFG | pm4net (.NET lib) or export for Disco/ProM |

---

## ğŸ— Pipeline Flow

Video + Audio
â†“
Frame extraction (1 fps) + audio chunks
â†“
Multimodal prompt â†’ zero-shot model
â†“
Predicted activity labels
â†“
Audio check (especially for â€œdropâ€)
â†“
Event Log (CSV)
â†“
Process Mining â†’ DFG

---

## ğŸ§  Prompt Engineering

The prompt describes the set of activities and provides instructions on how to recognize them.  
This is the **core** of the project.

> âœ… Zero-shot strategy = no training, prompt + foundation model only

---

## ğŸš€ How to Replicate

### Requirements
.NET 8+
Semantic Kernel
Ollama
FFmpeg

### Recommended models on Ollama

- `llava`
- `phi3-vision`
- `moondream`
- (if available) `llama-vision`

---

## ğŸ“ Reference Abstract

For the original abstract and detailed motivation of this research project, see:  
[Abstract â€“ â€œMultimodal Zero-Shot Activity Recognition for Process Mining of Robotic Systemsâ€](https://www.researchgate.net/publication/395101773_Multimodal_Zero-Shot_Activity_Recognition_for_Process_Mining_of_Robotic_Systems)  

---

## ğŸ“¦ Roadmap

- [ ] Video/audio extraction  
- [ ] Semantic Kernel prompt for recognition  
- [ ] Activity recognition pipeline  
- [ ] Audio-video fusion (detect â€œdropâ€)  
- [ ] Generate event log  
- [ ] Support pm4net + export to Disco/ProM  
- [ ] Visualize DFG  

---

Give this repository a â­ on GitHub and share it!

```bash
https://github.com/sofiacuccu00/MultimodalActivityRecognition_RoboticSystems.git
```
